{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer2People.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZLTS8ti9LuRn",
        "9cL3zDH1L0BZ",
        "6YmWQoDPL7LD",
        "P_icuXVoL9aL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "893lRA86LrFL",
        "colab_type": "text"
      },
      "source": [
        "# Transfer to People"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTS8ti9LuRn",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyaAE5Bn3gD3",
        "colab_type": "code",
        "outputId": "f66fc957-1168-4f8a-f422-053de4205b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# https://drive.google.com/uc?id=1eJnK7Vhj7ZwkVuqFZ9jl3szWdXbFbtKG\n",
        "import gdown\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1eJnK7Vhj7ZwkVuqFZ9jl3szWdXbFbtKG #https://drive.google.com/uc?id=1lLDZwQ0JiUM9FxTPGUGNQJhzBEkgm7x4\n",
        "!unzip -nq *.zip\n",
        "!gdown https://drive.google.com/uc?id=1JVOzQ0GRgm4wMVUgvBNH6YvgiruLGoJW\n",
        "#https://drive.google.com/uc?id=1RoH-Ev-xGgkn21yYo-7s8XKV11cNrI9B#https://drive.google.com/uc?id=1YtgNplAV_THzVuLslEHWORJUI-ibsRYA\n",
        "!gdown https://drive.google.com/uc?id=1LGrmFTourfHJ0f9TSa_ynaj6PEoVXVLm\n",
        "#https://drive.google.com/uc?id=1XEkoBdgoOTtWkumWLYRbvghYiysB8nPH#https://drive.google.com/uc?id=1F6r176ipTOmwgfrt-lyk293XuL5EhofH\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eJnK7Vhj7ZwkVuqFZ9jl3szWdXbFbtKG\n",
            "To: /content/CamouflageData.zip\n",
            "123MB [00:00, 201MB/s]\n",
            "CamouflageData/Camouﬂage pattern statement.txt:  mismatching \"local\" filename (CamouflageData/CamouямВage pattern statement.txt),\n",
            "         continuing with \"central\" filename version\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JVOzQ0GRgm4wMVUgvBNH6YvgiruLGoJW\n",
            "To: /content/fcnmodel\n",
            "95.8MB [00:00, 186MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LGrmFTourfHJ0f9TSa_ynaj6PEoVXVLm\n",
            "To: /content/vggmodel\n",
            "80.1MB [00:00, 193MB/s] \n",
            "CamouflageData\tCamouflageData.zip  fcnmodel  sample_data  vggmodel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VKL30PpZ9rq",
        "colab_type": "code",
        "outputId": "04d0c123-a1d1-4cb6-9914-bf3bd8bb954e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!zip file /content/CamouflageData/result_comparision/*"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: /content/CamouflageData/result_comparision/*\n",
            "\n",
            "zip error: Nothing to do! (file.zip)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1a3tMiD9J2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset\n",
        "from torchvision import utils\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.vgg import VGG\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cL3zDH1L0BZ",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0VlyzAaD-s7",
        "colab_type": "code",
        "outputId": "f3a291d9-ba0b-44b2-8309-ef893a861074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "root_dir = '/content/CamouflageData/'\n",
        "train_file = root_dir + 'train.csv'\n",
        "\n",
        "print(\"training csv exists:{}\".format(path.exists(train_file)))\n",
        "\n",
        "# the folder to save results for comparison\n",
        "folder_to_save_validation_result = root_dir + '/result_comparision/' \n",
        "\n",
        "if os.path.isdir(folder_to_save_validation_result) == False:\n",
        "    os.mkdir(folder_to_save_validation_result)\n",
        "\n",
        "# the number of segmentation classes\n",
        "num_class = 2 # 32 for original CamVid\n",
        "means     = np.array([103.939, 116.779, 123.68]) / 255. # mean of three channels in the order of BGR\n",
        "\n",
        "h, w      = 256, 256\n",
        "train_h = 256\n",
        "train_w = 256\n",
        "val_h = 256\n",
        "val_w = 256\n",
        "\n",
        "## parameters for Solver-Adam in this example\n",
        "batch_size = 6 #\n",
        "epochs     = 20 # don't try to improve the performance by simply increasing the training epochs or iterations\n",
        "lr         = 1e-4    # achieved besty results \n",
        "step_size  = 100 # Won't work when epochs <=100\n",
        "gamma      = 0.1#0.5 #\n",
        "pretrainOnCAMO = 0 \n",
        "#\n",
        "\n",
        "## index for validation images\n",
        "global_index = 0\n",
        "\n",
        "# pixel accuracy and mIOU list \n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "f_measure_list = []\n",
        "mae_list = []\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "num_gpu = list(range(torch.cuda.device_count()))\n",
        "\n",
        "class CamVidDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n",
        "        self.data      = pd.read_csv(csv_file)\n",
        "        self.means     = means\n",
        "        self.n_class   = n_class\n",
        "        self.flip_rate = flip_rate       \n",
        "\n",
        "        self.resize_h = h\n",
        "        self.resize_w = w        \n",
        "        \n",
        "        if phase == 'train':\n",
        "            self.new_h = train_h\n",
        "            self.new_w = train_w\n",
        "            self.crop = crop\n",
        "        elif phase == 'val':\n",
        "            self.flip_rate = 0.\n",
        "            self.crop = False # False\n",
        "            self.new_h = val_h\n",
        "            self.new_w = val_w\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name   = self.data.iloc[idx, 0]                \n",
        "        img_name = root_dir  + img_name                        \n",
        "        img = Image.open(img_name).convert('RGB')  \n",
        "        # img = img.resize((480, 360))\n",
        "        img = img.resize((256, 256))\n",
        "        label_name = self.data.iloc[idx, 1]        \n",
        "        label_name = root_dir  + label_name                       \n",
        "        label_image = Image.open(label_name).convert('L')\n",
        "        # label_image = label_image.resize((480, 360))\n",
        "        label_image = label_image.resize((256, 256))\n",
        "        label = np.asarray(label_image)\n",
        "\n",
        "\n",
        "\n",
        "        # In training mode, the crop strategy is random-shift crop.\n",
        "        # In validation model, it is center crop.\n",
        "        # if self.crop:            \n",
        "        #     w, h = img.size\n",
        "        #     A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n",
        "        #     A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n",
        "\n",
        "        #     img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        #     label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        # else:            \n",
        "        #     w, h = img.size\n",
        "        #     A_x_offset = int((w - self.new_w)/2)\n",
        "        #     A_y_offset = int((h - self.new_h)/2)\n",
        "            \n",
        "        #     img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "        #     label_image = label_image.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w, A_y_offset + self.new_h)) # left, top, right, bottom\n",
        "\n",
        "        #     label_image_h, label_image_w = label_image.size\n",
        "\n",
        "        # we could try to revise the values in label for reducing the number of segmentation classes\n",
        "        label = np.array(label_image)              \n",
        "        label = label/max(label.max(),1)\n",
        "        if random.random() < self.flip_rate:\n",
        "            img   = np.fliplr(img)\n",
        "            label = np.fliplr(label)\n",
        "        \n",
        "        # reduce mean in terms of BGR\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= self.means[0]\n",
        "        img[1] -= self.means[1]\n",
        "        img[2] -= self.means[2]\n",
        "\n",
        "        # convert to tensor\n",
        "        img = torch.from_numpy(img.copy()).float()\n",
        "        label = torch.from_numpy(label.copy()).long()\n",
        "\n",
        "        # create one-hot encoding\n",
        "        lst = [x for x in label.size()]\n",
        "        if len(lst)>2:\n",
        "          print(label_name)\n",
        "          print(lst)\n",
        "        h, w = label.size()\n",
        "        target = torch.zeros(self.n_class, h, w)\n",
        "        for c in range(self.n_class):\n",
        "            target[c][label == c] = 1\n",
        "\n",
        "        sample = {'X': img, 'Y': target, 'l': label, 'N': label_name}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "train_data = CamVidDataset(csv_file=train_file, phase='train')\n",
        "val_data = CamVidDataset(csv_file=train_file, phase='val')\n",
        "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "pivot = len(train_data) * 3 // 5\n",
        "train_data = Subset(train_data, range(0, pivot))\n",
        "val_data = Subset(val_data, range(pivot, len(val_data)))\n",
        "print(len(train_data), len(val_data))\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_data, batch_size=1, num_workers=8)\n",
        "\n",
        "# x = next(iter(train_loader))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training csv exists:True\n",
            "599 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdGrxL-kL4Yl",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKraXnLeD-lV",
        "colab_type": "code",
        "outputId": "71e00170-57a6-422f-e89e-6cd24a5a759f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:            \n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output\n",
        "\n",
        "class FCN8s(nn.Module):\n",
        "    #Ref: https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1\n",
        "    #The layer description is accordance with the above fiture instead of the original paper. Alex 2019/12/03 \n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score+x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn2(score+x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "        score = self.softmax(score)\n",
        "\n",
        "        # score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        # score = self.bn1(score)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)                      \n",
        "        # score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        # score = self.bn2(score)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)           \n",
        "        # score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        # score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        # score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        # score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "# load pretrained weights and define FCN8s\n",
        "\n",
        "if pretrainOnCAMO:\n",
        "    vgg_model = torch.load('/content/vggmodel')\n",
        "    fcn_model = torch.load('/content/fcnmodel')\n",
        "else:\n",
        "    vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
        "    fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n",
        "\n",
        "\n",
        "ts = time.time()\n",
        "vgg_model = vgg_model.cuda()\n",
        "fcn_model = fcn_model.cuda()\n",
        "fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
        "print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
        "\n",
        "# criterion=new_loss\n",
        "# criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = FocalLoss()\n",
        "# criterion = DiceLoss()\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "print(fcn_model) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish cuda loading, time elapsed 0.027231693267822266\n",
            "DataParallel(\n",
            "  (module): FCN8s(\n",
            "    (pretrained_net): VGGNet(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (8): ReLU(inplace=True)\n",
            "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (11): ReLU(inplace=True)\n",
            "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (15): ReLU(inplace=True)\n",
            "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (18): ReLU(inplace=True)\n",
            "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (20): ReLU(inplace=True)\n",
            "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (22): ReLU(inplace=True)\n",
            "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (25): ReLU(inplace=True)\n",
            "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (27): ReLU(inplace=True)\n",
            "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (29): ReLU(inplace=True)\n",
            "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    )\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (classifier): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (softmax): LogSoftmax()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YmWQoDPL7LD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UADtIeFHD-hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        ts = time.time()\n",
        "        for iter, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = Variable(batch['X'].cuda())\n",
        "                labels = Variable(batch['Y'].cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
        "            outputs = fcn_model(inputs)\n",
        "            # # !!!!!!!\n",
        "            # print(outputs)\n",
        "            \n",
        "            # print(\"!!!!!!\")\n",
        "            # print(labels)\n",
        "            # # !!!!!!!\n",
        "            # weights=[1/((labels==1).numel()),1/((labels==0).numel())]\n",
        "            # pos_weight=torch.tensor((labels==0).numel()/(labels==1).numel()).cuda()*1.5\n",
        "            criterion=nn.BCEWithLogitsLoss()\n",
        "            # criterion = nn.L1Loss()\n",
        "            # loss=criterion.forward(input=m(outputs),target=labels.type(torch.LongTensor).cuda())\n",
        "\n",
        "            labels/=max(labels.max(),1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iter % 10 == 0:\n",
        "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.data.item()))\n",
        "        \n",
        "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
        "        \n",
        "\n",
        "        val(epoch)\n",
        "        fcn_model.train()\n",
        "        \n",
        "    highest_pixel_acc = max(pixel_acc_list)\n",
        "    highest_mIOU = max(mIOU_list)\n",
        "    highest_f_measure = max(f_measure_list)\n",
        "    lowest_mae = min(mae_list)        \n",
        "    \n",
        "    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n",
        "    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n",
        "    highest_f_measure_epoch = f_measure_list.index(highest_f_measure)\n",
        "    lowest_mae_epoch = mae_list.index(lowest_mae)\n",
        "    \n",
        "    print(\"The highest mIOU is {} and is achieved at epoch-{}\".format(highest_mIOU, highest_mIOU_epoch))\n",
        "    print(\"The lowest MAE is {} and is achieved at epoch-{}\".format(lowest_mae, lowest_mae_epoch))\n",
        "    print(\"The highest f-measure is {} and is achieved at epoch-{}\".format(highest_f_measure, highest_f_measure_epoch))\n",
        "\n",
        "\n",
        "def save_result_comparison(input_np, output_np, gt_path):\n",
        "    print(gt_path)\n",
        "    means     = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "    \n",
        "    global global_index\n",
        "    \n",
        "    original_im_RGB = np.zeros((256,256,3))    \n",
        "    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n",
        "    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n",
        "    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n",
        "\n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n",
        "\n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n",
        "    \n",
        "    im_seg_RGB = np.zeros((256,256,3))\n",
        "\n",
        "    # the following version is designed for 11-class version and could still work if the number of classes is fewer.\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if output_np[i,j] == 0:\n",
        "                im_seg_RGB[i,j,:] = [0, 0, 0]\n",
        "            elif output_np[i,j] == 1:  \n",
        "                im_seg_RGB[i,j,:] = [255, 255, 255]\n",
        "            elif output_np[i,j] == 2:  \n",
        "                im_seg_RGB[i,j,:] = [192, 192, 128]    \n",
        "            elif output_np[i,j] == 3:  \n",
        "                im_seg_RGB[i,j,:] = [128, 64, 128]    \n",
        "            elif output_np[i,j] == 4:  \n",
        "                im_seg_RGB[i,j,:] = [0, 0, 192]    \n",
        "            elif output_np[i,j] == 5:  \n",
        "                im_seg_RGB[i,j,:] = [128, 128, 0]    \n",
        "            elif output_np[i,j] == 6:  \n",
        "                im_seg_RGB[i,j,:] = [192, 128, 128]    \n",
        "            elif output_np[i,j] == 7:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 128]    \n",
        "            elif output_np[i,j] == 8:  \n",
        "                im_seg_RGB[i,j,:] = [64, 0, 128]    \n",
        "            elif output_np[i,j] == 9:  \n",
        "                im_seg_RGB[i,j,:] = [64, 64, 0]    \n",
        "            elif output_np[i,j] == 10:  \n",
        "                im_seg_RGB[i,j,:] = [0, 128, 192]    \n",
        "                    \n",
        "    # horizontally stack original image and its corresponding segmentation results \n",
        "    gt_image = Image.open(gt_path).convert('RGB')\n",
        "    gt_image = gt_image.resize((256, 256))\n",
        "    slicing_vertical = np.ones((256, 2, 3)) * 255.0\n",
        "    hstack_image = np.hstack((original_im_RGB, slicing_vertical, im_seg_RGB, slicing_vertical, gt_image))             \n",
        "    return hstack_image\n",
        "    \n",
        "def save_image(image_stack):\n",
        "    global global_index\n",
        "    stack = []\n",
        "    slicing_horizontal = np.ones((2, 772, 3)) * 255.0\n",
        "    for i in image_stack:\n",
        "        stack.append(i)\n",
        "        stack.append(slicing_horizontal)\n",
        "    vstack_image = np.vstack(stack)\n",
        "    new_im = Image.fromarray(np.uint8(vstack_image))\n",
        "    \n",
        "    file_name = folder_to_save_validation_result + str(global_index) + '.jpg'\n",
        "        \n",
        "    global_index = global_index + 1\n",
        "        \n",
        "    new_im.save(file_name)  \n",
        "\n",
        "# train()     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_icuXVoL9aL",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl0WVeoTD-be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(epoch):\n",
        "    fcn_model.eval()\n",
        "    total_ious = []\n",
        "    pixel_accs = []\n",
        "    f_measures = []\n",
        "    maes = []\n",
        "    numberOfImage = 4\n",
        "    \n",
        "    for iter, batch in enumerate(val_loader): ## batch is 1 in this case\n",
        "        if use_gpu:\n",
        "            inputs = Variable(batch['X'].cuda())\n",
        "        else:\n",
        "            inputs = Variable(batch['X'])        \n",
        "\n",
        "        output = fcn_model(inputs)                                \n",
        "        \n",
        "        # only save the 1st image for comparison\n",
        "\n",
        "        if iter <= numberOfImage:\n",
        "            print('---------iter={}'.format(iter))\n",
        "            if iter == 0:\n",
        "                vstack_image = [] \n",
        "            # generate images\n",
        "            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n",
        "            image = images[0,:,:]        \n",
        "            image = save_result_comparison(batch['X'], image, batch['N'][0])\n",
        "            vstack_image.append(image)\n",
        "            print(batch['N'])\n",
        "            if iter == numberOfImage:\n",
        "                save_image(vstack_image)\n",
        "\n",
        "                            \n",
        "        output = output.data.cpu().numpy()\n",
        "\n",
        "        N, _, h, w = output.shape                \n",
        "        pred = output.transpose(0, 2, 3, 1).reshape(-1, num_class).argmax(axis=1).reshape(N, h, w)        \n",
        "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
        "\n",
        "        for p, t in zip(pred, target):\n",
        "            total_ious.append(iou(p, t))\n",
        "            pixel_accs.append(pixel_acc(p, t))\n",
        "            f_measures.append(F_Measure(p, t))\n",
        "            maes.append(MAE(p, t))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
        "    ious = np.nanmean(total_ious, axis=1)\n",
        "    pixel_accs = np.array(pixel_accs).mean()\n",
        "    f_measures = np.nanmean(np.array(f_measures))\n",
        "    maes = np.array(maes).mean()\n",
        "    print(\"epoch{}, MAE: {}, meanIoU: {}, f_measure: {}, IoUs: {}\".format(epoch, maes, np.nanmean(ious), f_measures, ious))\n",
        "    \n",
        "    global pixel_acc_list\n",
        "    global mIOU_list\n",
        "    global f_measure_list\n",
        "    global mae_list\n",
        "    \n",
        "    pixel_acc_list.append(pixel_accs)\n",
        "    mIOU_list.append(np.nanmean(ious))\n",
        "    f_measure_list.append(f_measures)\n",
        "    mae_list.append(maes)\n",
        "\n",
        "\n",
        "# borrow functions and modify it from https://github.com/Kaixhin/FCN-semantic-segmentation/blob/master/main.py\n",
        "# Calculates class intersections over unions\n",
        "def iou(pred, target):\n",
        "    ious = []\n",
        "    target=target/max(target.max(),1)\n",
        "    for cls in range(num_class):\n",
        "        pred_inds = pred == cls\n",
        "        target_inds = target == cls\n",
        "        intersection = pred_inds[target_inds].sum()\n",
        "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
        "        # if(cls==1):\n",
        "        #     print(pred_inds.sum())\n",
        "        #     print(target_inds.sum())\n",
        "        #     print(intersection)\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # if there is no ground truth, do not include in evaluation\n",
        "        else:\n",
        "            ious.append(float(intersection) / max(union, 1))\n",
        "        # print(\"cls\", cls, pred_inds.sum(), target_inds.sum(), intersection, float(intersection) / max(union, 1))\\\n",
        "    \n",
        "    return ious\n",
        "\n",
        "\n",
        "def pixel_acc(pred, target):\n",
        "    correct = (pred == target).sum()\n",
        "    total   = (target == target).sum()\n",
        "    return correct / total\n",
        "\n",
        "def F_Measure(pred, target):\n",
        "    beta_sqr = 0.3\n",
        "    target=target/max(target.max(),1)\n",
        "    cls = 1\n",
        "    pred_inds = pred == cls\n",
        "    target_inds = target == cls\n",
        "    TP = pred_inds[target_inds].sum()\n",
        "    FP = pred_inds.sum() - TP\n",
        "    FN = target_inds.sum() - TP\n",
        "    P = TP / (TP + FP)\n",
        "    R = TP / (TP + FN)\n",
        "    denominator = (beta_sqr*P + R)\n",
        "    # print(P, R)\n",
        "    if denominator == 0:\n",
        "        return float('nan') # if there is no ground truth, do not include in evaluation\n",
        "    else:\n",
        "        f_measure = (beta_sqr + 1) * P * R / denominator\n",
        "        return f_measure\n",
        "\n",
        "def MAE(pred, target):\n",
        "    target=target/max(target.max(),1)\n",
        "    pred = torch.from_numpy(pred).float()\n",
        "    target = torch.from_numpy(target).float()\n",
        "    # print(type(target[0][0]))\n",
        "    loss = nn.L1Loss()\n",
        "    mae= loss(pred, target)\n",
        "    return mae\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZz-zbB7MAtW",
        "colab_type": "text"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujsJzHISD-Ru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfc8c141-88b7-4a6b-b145-4c322ca4448c"
      },
      "source": [
        "## perform training and validation\n",
        "global_index = 0\n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "f_measure_list = []\n",
        "mae_list = []\n",
        "# val(0)  # show the accuracy before training\n",
        "train()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch0, iter0, loss: 0.7670866847038269\n",
            "epoch0, iter10, loss: 0.7504005432128906\n",
            "epoch0, iter20, loss: 0.7239148616790771\n",
            "epoch0, iter30, loss: 0.7128188610076904\n",
            "epoch0, iter40, loss: 0.7113524675369263\n",
            "epoch0, iter50, loss: 0.69992995262146\n",
            "epoch0, iter60, loss: 0.7097325325012207\n",
            "epoch0, iter70, loss: 0.7209722995758057\n",
            "epoch0, iter80, loss: 0.7340807318687439\n",
            "epoch0, iter90, loss: 0.6764329671859741\n",
            "Finish epoch 0, time elapsed 11.751632452011108\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch0, MAE: 0.020953979343175888, meanIoU: 0.6472535120601455, f_measure: 0.4148380287477071, IoUs: [0.97841044 0.31609658]\n",
            "epoch1, iter0, loss: 0.6972002983093262\n",
            "epoch1, iter10, loss: 0.6793102025985718\n",
            "epoch1, iter20, loss: 0.6446554064750671\n",
            "epoch1, iter30, loss: 0.6860460042953491\n",
            "epoch1, iter40, loss: 0.6935588717460632\n",
            "epoch1, iter50, loss: 0.6956334114074707\n",
            "epoch1, iter60, loss: 0.6878165006637573\n",
            "epoch1, iter70, loss: 0.6744732856750488\n",
            "epoch1, iter80, loss: 0.6747610569000244\n",
            "epoch1, iter90, loss: 0.5942286849021912\n",
            "Finish epoch 1, time elapsed 11.709123134613037\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch1, MAE: 0.011626853607594967, meanIoU: 0.686790037691962, f_measure: 0.5399660950791585, IoUs: [0.98796521 0.38561487]\n",
            "epoch2, iter0, loss: 0.6285372972488403\n",
            "epoch2, iter10, loss: 0.710934579372406\n",
            "epoch2, iter20, loss: 0.6708452701568604\n",
            "epoch2, iter30, loss: 0.6145437955856323\n",
            "epoch2, iter40, loss: 0.6341570615768433\n",
            "epoch2, iter50, loss: 0.6366907358169556\n",
            "epoch2, iter60, loss: 0.6589551568031311\n",
            "epoch2, iter70, loss: 0.673959493637085\n",
            "epoch2, iter80, loss: 0.6418968439102173\n",
            "epoch2, iter90, loss: 0.6039507389068604\n",
            "Finish epoch 2, time elapsed 11.69123387336731\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch2, MAE: 0.010153541341423988, meanIoU: 0.7147992885908017, f_measure: 0.609783793958296, IoUs: [0.98940765 0.44019093]\n",
            "epoch3, iter0, loss: 0.6527604460716248\n",
            "epoch3, iter10, loss: 0.6069803833961487\n",
            "epoch3, iter20, loss: 0.5990391969680786\n",
            "epoch3, iter30, loss: 0.5867156386375427\n",
            "epoch3, iter40, loss: 0.6451048254966736\n",
            "epoch3, iter50, loss: 0.6273333430290222\n",
            "epoch3, iter60, loss: 0.5662198066711426\n",
            "epoch3, iter70, loss: 0.6418227553367615\n",
            "epoch3, iter80, loss: 0.6208683252334595\n",
            "epoch3, iter90, loss: 0.6313261389732361\n",
            "Finish epoch 3, time elapsed 11.650862455368042\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch3, MAE: 0.014509659260511398, meanIoU: 0.7113501718659323, f_measure: 0.5459666698080584, IoUs: [0.98490663 0.43779371]\n",
            "epoch4, iter0, loss: 0.5849701166152954\n",
            "epoch4, iter10, loss: 0.5864987969398499\n",
            "epoch4, iter20, loss: 0.5967570543289185\n",
            "epoch4, iter30, loss: 0.5525960326194763\n",
            "epoch4, iter40, loss: 0.5999479293823242\n",
            "epoch4, iter50, loss: 0.5630814433097839\n",
            "epoch4, iter60, loss: 0.6069662570953369\n",
            "epoch4, iter70, loss: 0.518727719783783\n",
            "epoch4, iter80, loss: 0.5737124681472778\n",
            "epoch4, iter90, loss: 0.6129649877548218\n",
            "Finish epoch 4, time elapsed 11.650720119476318\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch4, MAE: 0.009203186258673668, meanIoU: 0.7430719886130608, f_measure: 0.6470166698942482, IoUs: [0.99046377 0.49568021]\n",
            "epoch5, iter0, loss: 0.5897554159164429\n",
            "epoch5, iter10, loss: 0.5376526713371277\n",
            "epoch5, iter20, loss: 0.5563112497329712\n",
            "epoch5, iter30, loss: 0.5796477794647217\n",
            "epoch5, iter40, loss: 0.559638500213623\n",
            "epoch5, iter50, loss: 0.5110921859741211\n",
            "epoch5, iter60, loss: 0.5377052426338196\n",
            "epoch5, iter70, loss: 0.5244283676147461\n",
            "epoch5, iter80, loss: 0.5089321136474609\n",
            "epoch5, iter90, loss: 0.5045894980430603\n",
            "Finish epoch 5, time elapsed 11.641725063323975\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch5, MAE: 0.007993736304342747, meanIoU: 0.7541475668489303, f_measure: 0.6971121144468984, IoUs: [0.99170011 0.51659503]\n",
            "epoch6, iter0, loss: 0.4026995599269867\n",
            "epoch6, iter10, loss: 0.5264096260070801\n",
            "epoch6, iter20, loss: 0.5080222487449646\n",
            "epoch6, iter30, loss: 0.544064998626709\n",
            "epoch6, iter40, loss: 0.53254234790802\n",
            "epoch6, iter50, loss: 0.46903297305107117\n",
            "epoch6, iter60, loss: 0.5117618441581726\n",
            "epoch6, iter70, loss: 0.4890156388282776\n",
            "epoch6, iter80, loss: 0.5286283493041992\n",
            "epoch6, iter90, loss: 0.5494198799133301\n",
            "Finish epoch 6, time elapsed 11.630122900009155\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch6, MAE: 0.007826690562069416, meanIoU: 0.7201515745742703, f_measure: 0.7119294170039873, IoUs: [0.99189073 0.44841242]\n",
            "epoch7, iter0, loss: 0.4965292811393738\n",
            "epoch7, iter10, loss: 0.4654882848262787\n",
            "epoch7, iter20, loss: 0.49344325065612793\n",
            "epoch7, iter30, loss: 0.44458383321762085\n",
            "epoch7, iter40, loss: 0.453040212392807\n",
            "epoch7, iter50, loss: 0.45500749349594116\n",
            "epoch7, iter60, loss: 0.44367319345474243\n",
            "epoch7, iter70, loss: 0.5287302136421204\n",
            "epoch7, iter80, loss: 0.5756453275680542\n",
            "epoch7, iter90, loss: 0.5618848204612732\n",
            "Finish epoch 7, time elapsed 11.724530935287476\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch7, MAE: 0.011172103695571423, meanIoU: 0.6987639358706441, f_measure: 0.6030030101995423, IoUs: [0.98848614 0.40904174]\n",
            "epoch8, iter0, loss: 0.605818510055542\n",
            "epoch8, iter10, loss: 0.5113173723220825\n",
            "epoch8, iter20, loss: 0.505369246006012\n",
            "epoch8, iter30, loss: 0.47258687019348145\n",
            "epoch8, iter40, loss: 0.45401668548583984\n",
            "epoch8, iter50, loss: 0.49677523970603943\n",
            "epoch8, iter60, loss: 0.45757874846458435\n",
            "epoch8, iter70, loss: 0.5269434452056885\n",
            "epoch8, iter80, loss: 0.5094975233078003\n",
            "epoch8, iter90, loss: 0.49715203046798706\n",
            "Finish epoch 8, time elapsed 11.725977420806885\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch8, MAE: 0.008446769788861275, meanIoU: 0.7309337964176366, f_measure: 0.7114813393249152, IoUs: [0.99117612 0.47069147]\n",
            "epoch9, iter0, loss: 0.48707446455955505\n",
            "epoch9, iter10, loss: 0.47385284304618835\n",
            "epoch9, iter20, loss: 0.4164675176143646\n",
            "epoch9, iter30, loss: 0.4698150157928467\n",
            "epoch9, iter40, loss: 0.4138939380645752\n",
            "epoch9, iter50, loss: 0.43230900168418884\n",
            "epoch9, iter60, loss: 0.4259822368621826\n",
            "epoch9, iter70, loss: 0.4142744541168213\n",
            "epoch9, iter80, loss: 0.44999322295188904\n",
            "epoch9, iter90, loss: 0.43594449758529663\n",
            "Finish epoch 9, time elapsed 11.725519180297852\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch9, MAE: 0.008444556966423988, meanIoU: 0.7255839253720011, f_measure: 0.7117790787108856, IoUs: [0.9912643  0.45990355]\n",
            "epoch10, iter0, loss: 0.43935656547546387\n",
            "epoch10, iter10, loss: 0.438884973526001\n",
            "epoch10, iter20, loss: 0.44388341903686523\n",
            "epoch10, iter30, loss: 0.399021714925766\n",
            "epoch10, iter40, loss: 0.4427220821380615\n",
            "epoch10, iter50, loss: 0.4268742799758911\n",
            "epoch10, iter60, loss: 0.459716260433197\n",
            "epoch10, iter70, loss: 0.4169289469718933\n",
            "epoch10, iter80, loss: 0.441153347492218\n",
            "epoch10, iter90, loss: 0.38745149970054626\n",
            "Finish epoch 10, time elapsed 11.678047180175781\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch10, MAE: 0.007013931404799223, meanIoU: 0.7308807387611956, f_measure: 0.7587519631938224, IoUs: [0.99274904 0.46901244]\n",
            "epoch11, iter0, loss: 0.45303964614868164\n",
            "epoch11, iter10, loss: 0.4113663136959076\n",
            "epoch11, iter20, loss: 0.41699323058128357\n",
            "epoch11, iter30, loss: 0.40191614627838135\n",
            "epoch11, iter40, loss: 0.40002331137657166\n",
            "epoch11, iter50, loss: 0.4186532497406006\n",
            "epoch11, iter60, loss: 0.4435170590877533\n",
            "epoch11, iter70, loss: 0.4200509786605835\n",
            "epoch11, iter80, loss: 0.3704070746898651\n",
            "epoch11, iter90, loss: 0.41564592719078064\n",
            "Finish epoch 11, time elapsed 11.709128618240356\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch11, MAE: 0.008394012227654457, meanIoU: 0.7520351743933205, f_measure: 0.7030678461476926, IoUs: [0.99130362 0.51276673]\n",
            "epoch12, iter0, loss: 0.385287344455719\n",
            "epoch12, iter10, loss: 0.3862867057323456\n",
            "epoch12, iter20, loss: 0.4305410087108612\n",
            "epoch12, iter30, loss: 0.4582907557487488\n",
            "epoch12, iter40, loss: 0.4106365144252777\n",
            "epoch12, iter50, loss: 0.4188222289085388\n",
            "epoch12, iter60, loss: 0.43070483207702637\n",
            "epoch12, iter70, loss: 0.45291122794151306\n",
            "epoch12, iter80, loss: 0.43916720151901245\n",
            "epoch12, iter90, loss: 0.46173858642578125\n",
            "Finish epoch 12, time elapsed 11.693379878997803\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch12, MAE: 0.0073831938207149506, meanIoU: 0.7049712938710005, f_measure: 0.7671775750531832, IoUs: [0.99237286 0.41756973]\n",
            "epoch13, iter0, loss: 0.4600171446800232\n",
            "epoch13, iter10, loss: 0.3961660861968994\n",
            "epoch13, iter20, loss: 0.41554293036460876\n",
            "epoch13, iter30, loss: 0.3833414316177368\n",
            "epoch13, iter40, loss: 0.4288713335990906\n",
            "epoch13, iter50, loss: 0.37009701132774353\n",
            "epoch13, iter60, loss: 0.4106370210647583\n",
            "epoch13, iter70, loss: 0.3986539840698242\n",
            "epoch13, iter80, loss: 0.3881756663322449\n",
            "epoch13, iter90, loss: 0.3702499568462372\n",
            "Finish epoch 13, time elapsed 11.688072204589844\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch13, MAE: 0.006206550635397434, meanIoU: 0.7664563463754854, f_measure: 0.7502095225925243, IoUs: [0.99357205 0.53934064]\n",
            "epoch14, iter0, loss: 0.3817386329174042\n",
            "epoch14, iter10, loss: 0.42844825983047485\n",
            "epoch14, iter20, loss: 0.3871845602989197\n",
            "epoch14, iter30, loss: 0.3747263550758362\n",
            "epoch14, iter40, loss: 0.41353291273117065\n",
            "epoch14, iter50, loss: 0.40062153339385986\n",
            "epoch14, iter60, loss: 0.3828585147857666\n",
            "epoch14, iter70, loss: 0.3863738477230072\n",
            "epoch14, iter80, loss: 0.38603824377059937\n",
            "epoch14, iter90, loss: 0.3747345805168152\n",
            "Finish epoch 14, time elapsed 11.648759603500366\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch14, MAE: 0.006137199234217405, meanIoU: 0.7771778581735832, f_measure: 0.7644971148196775, IoUs: [0.99363257 0.56072315]\n",
            "epoch15, iter0, loss: 0.39869293570518494\n",
            "epoch15, iter10, loss: 0.38341617584228516\n",
            "epoch15, iter20, loss: 0.3841288089752197\n",
            "epoch15, iter30, loss: 0.39083313941955566\n",
            "epoch15, iter40, loss: 0.3760097026824951\n",
            "epoch15, iter50, loss: 0.3965919017791748\n",
            "epoch15, iter60, loss: 0.40056246519088745\n",
            "epoch15, iter70, loss: 0.37456101179122925\n",
            "epoch15, iter80, loss: 0.38957715034484863\n",
            "epoch15, iter90, loss: 0.37580713629722595\n",
            "Finish epoch 15, time elapsed 11.655815839767456\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch15, MAE: 0.005871353205293417, meanIoU: 0.7691672875710385, f_measure: 0.7764550877689965, IoUs: [0.99393186 0.54440272]\n",
            "epoch16, iter0, loss: 0.38008421659469604\n",
            "epoch16, iter10, loss: 0.40181177854537964\n",
            "epoch16, iter20, loss: 0.36858662962913513\n",
            "epoch16, iter30, loss: 0.3849968910217285\n",
            "epoch16, iter40, loss: 0.3670954406261444\n",
            "epoch16, iter50, loss: 0.39275288581848145\n",
            "epoch16, iter60, loss: 0.3873669505119324\n",
            "epoch16, iter70, loss: 0.37450331449508667\n",
            "epoch16, iter80, loss: 0.3985423445701599\n",
            "epoch16, iter90, loss: 0.3778759837150574\n",
            "Finish epoch 16, time elapsed 11.698883533477783\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch16, MAE: 0.005805244669318199, meanIoU: 0.786824129888259, f_measure: 0.7733225229755123, IoUs: [0.99399378 0.57965448]\n",
            "epoch17, iter0, loss: 0.3682335615158081\n",
            "epoch17, iter10, loss: 0.370458722114563\n",
            "epoch17, iter20, loss: 0.3718807101249695\n",
            "epoch17, iter30, loss: 0.39125382900238037\n",
            "epoch17, iter40, loss: 0.3843160569667816\n",
            "epoch17, iter50, loss: 0.3635365962982178\n",
            "epoch17, iter60, loss: 0.3748103976249695\n",
            "epoch17, iter70, loss: 0.3680095076560974\n",
            "epoch17, iter80, loss: 0.3861030340194702\n",
            "epoch17, iter90, loss: 0.3759191036224365\n",
            "Finish epoch 17, time elapsed 11.650049209594727\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch17, MAE: 0.007038269191980362, meanIoU: 0.7569834605845821, f_measure: 0.7544535074054796, IoUs: [0.99269438 0.52127254]\n",
            "epoch18, iter0, loss: 0.3837498128414154\n",
            "epoch18, iter10, loss: 0.37105298042297363\n",
            "epoch18, iter20, loss: 0.40798115730285645\n",
            "epoch18, iter30, loss: 0.3943902254104614\n",
            "epoch18, iter40, loss: 0.37112388014793396\n",
            "epoch18, iter50, loss: 0.3903349041938782\n",
            "epoch18, iter60, loss: 0.3921063542366028\n",
            "epoch18, iter70, loss: 0.3644956052303314\n",
            "epoch18, iter80, loss: 0.37034139037132263\n",
            "epoch18, iter90, loss: 0.37694936990737915\n",
            "Finish epoch 18, time elapsed 11.654751300811768\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch18, MAE: 0.006049575749784708, meanIoU: 0.7610054578636929, f_measure: 0.7742103735531939, IoUs: [0.99374602 0.5282649 ]\n",
            "epoch19, iter0, loss: 0.3650404214859009\n",
            "epoch19, iter10, loss: 0.37281525135040283\n",
            "epoch19, iter20, loss: 0.37276726961135864\n",
            "epoch19, iter30, loss: 0.3633408546447754\n",
            "epoch19, iter40, loss: 0.3905876576900482\n",
            "epoch19, iter50, loss: 0.36719411611557007\n",
            "epoch19, iter60, loss: 0.3615736961364746\n",
            "epoch19, iter70, loss: 0.36909279227256775\n",
            "epoch19, iter80, loss: 0.375506728887558\n",
            "epoch19, iter90, loss: 0.36587461829185486\n",
            "Finish epoch 19, time elapsed 11.705239295959473\n",
            "---------iter=0\n",
            "/content/CamouflageData/gt/dataset16_09_00013023.png\n",
            "['/content/CamouflageData/gt/dataset16_09_00013023.png']\n",
            "---------iter=1\n",
            "/content/CamouflageData/gt/dataset15_03_00003495.png\n",
            "['/content/CamouflageData/gt/dataset15_03_00003495.png']\n",
            "---------iter=2\n",
            "/content/CamouflageData/gt/dataset16_02_00002904.png\n",
            "['/content/CamouflageData/gt/dataset16_02_00002904.png']\n",
            "---------iter=3\n",
            "/content/CamouflageData/gt/dataset11_12_00016167.png\n",
            "['/content/CamouflageData/gt/dataset11_12_00016167.png']\n",
            "---------iter=4\n",
            "/content/CamouflageData/gt/dataset08_07_00007923.png\n",
            "['/content/CamouflageData/gt/dataset08_07_00007923.png']\n",
            "epoch19, MAE: 0.00587387103587389, meanIoU: 0.7753432964710028, f_measure: 0.7857142411863764, IoUs: [0.99393055 0.55675604]\n",
            "The highest mIOU is 0.786824129888259 and is achieved at epoch-16\n",
            "The lowest MAE is 0.005805244669318199 and is achieved at epoch-16\n",
            "The highest f-measure is 0.7857142411863764 and is achieved at epoch-19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20qijkJUChVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}