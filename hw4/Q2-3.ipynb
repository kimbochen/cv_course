{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH_0P9Nbb6F5",
        "colab_type": "text"
      },
      "source": [
        "# Homework 4-2 Semantic Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp827NH8cKol",
        "colab_type": "text"
      },
      "source": [
        "## Intialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjV2Jlvv8vlS",
        "colab_type": "code",
        "outputId": "f6368480-505a-4450-96c7-2d34c9c961ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1URM63okiWqDsOxMO_JCch1YHCq5Pg3tO\n",
        "!unzip -nq *.zip\n",
        "!ls --hide=CamVid | xargs rm -r\n",
        "%cd CamVid/\n",
        "!rm -r result_comparision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1URM63okiWqDsOxMO_JCch1YHCq5Pg3tO\n",
            "To: /content/HW4_updated1.zip\n",
            "145MB [00:00, 158MB/s] \n",
            "/content/CamVid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWmPZKyZ8gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.vgg import VGG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w4B03DY9PrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the seed for reproducibility\n",
        "seed = 309\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmarks = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlD_FJ5c2TYY",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset and Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzL2KhcaI9u",
        "colab_type": "code",
        "outputId": "d65326c0-b3ea-4a02-a6bc-64f1a64624b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "root_dir = Path('/content/CamVid')\n",
        "train_file = root_dir / 'train.csv'\n",
        "val_file = root_dir / 'val.csv'\n",
        "\n",
        "print(f'training csv exists:{train_file.exists()}')\n",
        "print(f'validation csv exists:{val_file.exists()}')\n",
        "\n",
        "folder_to_save_validation_result = root_dir / 'result_comparison'\n",
        "\n",
        "if folder_to_save_validation_result.exists() == False:\n",
        "    folder_to_save_validation_result.mkdir()\n",
        "\n",
        "# the number of segmentation classes, 32 for original CamVid\n",
        "num_class = 3\n",
        "\n",
        "# mean of three channels in the order of BGR\n",
        "means = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "\n",
        "h, w = 256, 256\n",
        "train_h, train_w = 256, 256\n",
        "val_h, val_w = 256, 256\n",
        "\n",
        "# parameters for Solver-Adam in this example\n",
        "batch_size = 6\n",
        "epochs     = 20\n",
        "lr         = 1e-4\n",
        "step_size  = 100\n",
        "gamma      = 0.5\n",
        "\n",
        "# index for validation images\n",
        "global_index = 0\n",
        "\n",
        "# pixel accuracy and mIOU list \n",
        "pixel_acc_list = []\n",
        "mIOU_list = []\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "num_gpu = list(range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "class CamVidDataset(Dataset):\n",
        "    def __init__(self, csv_file, phase, n_class=num_class, crop=True, flip_rate=0.5):\n",
        "        self.data      = pd.read_csv(csv_file)\n",
        "        self.means     = means\n",
        "        self.n_class   = n_class\n",
        "        self.flip_rate = flip_rate       \n",
        "\n",
        "        self.resize_h = h\n",
        "        self.resize_w = w        \n",
        "\n",
        "        if phase == 'train':\n",
        "            self.new_h = train_h\n",
        "            self.new_w = train_w\n",
        "            self.crop = crop\n",
        "        elif phase == 'val':\n",
        "            self.flip_rate = 0.\n",
        "            self.crop = False\n",
        "            self.new_h = val_h\n",
        "            self.new_w = val_w\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name   = self.data.iloc[idx, 0]\n",
        "        img_name = root_dir / img_name\n",
        "        img = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        label_name = self.data.iloc[idx, 1]        \n",
        "        label_name = root_dir / label_name                       \n",
        "        label_image = Image.open(label_name)\n",
        "        label = np.asarray(label_image)\n",
        "\n",
        "        # In training mode, the crop strategy is random-shift crop.\n",
        "        # In validation model, it is center crop.\n",
        "        if self.crop:\n",
        "            w, h = img.size\n",
        "            A_x_offset = np.int32(np.random.randint(0, w - self.new_w + 1, 1))[0]\n",
        "            A_y_offset = np.int32(np.random.randint(0, h - self.new_h + 1, 1))[0]\n",
        "\n",
        "            # left, top, right, bottom\n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w,\n",
        "                            A_y_offset + self.new_h))\n",
        "            # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset,\n",
        "                                            A_x_offset + self.new_w,\n",
        "                                            A_y_offset + self.new_h))\n",
        "        else:\n",
        "            w, h = img.size\n",
        "            A_x_offset = int((w - self.new_w)/2)\n",
        "            A_y_offset = int((h - self.new_h)/2)\n",
        "\n",
        "            # left, top, right, bottom\n",
        "            img = img.crop((A_x_offset, A_y_offset, A_x_offset + self.new_w,\n",
        "                            A_y_offset + self.new_h))\n",
        "            # left, top, right, bottom\n",
        "            label_image = label_image.crop((A_x_offset, A_y_offset,\n",
        "                                            A_x_offset + self.new_w,\n",
        "                                            A_y_offset + self.new_h))\n",
        "\n",
        "            label_image_h, label_image_w = label_image.size\n",
        "\n",
        "        # we could try to revise the values in label for \n",
        "        # reducing the number of segmentation classes\n",
        "        label = np.array(label_image)\n",
        "\n",
        "        # Class 1\n",
        "        mask_class1 = (label > 0) & (label < 8) | (label > 10)\n",
        "        label[mask_class1] = 1\n",
        "\n",
        "        # Class 2\n",
        "        mask_class2 = (label > 7) & (label < 11)\n",
        "        label[mask_class2] = 2\n",
        "\n",
        "        if random.random() < self.flip_rate:\n",
        "            img   = np.fliplr(img)\n",
        "            label = np.fliplr(label)\n",
        "        \n",
        "        # reduce mean in terms of BGR\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= self.means[0]\n",
        "        img[1] -= self.means[1]\n",
        "        img[2] -= self.means[2]\n",
        "\n",
        "        # convert to tensor\n",
        "        img = torch.from_numpy(img.copy()).float()\n",
        "        label = torch.from_numpy(label.copy()).long()\n",
        "\n",
        "        # create one-hot encoding\n",
        "        h, w = label.size()\n",
        "        target = torch.zeros(self.n_class, h, w)\n",
        "        for c in range(self.n_class):\n",
        "            target[c][label == c] = 1\n",
        "\n",
        "        sample = {'X': img, 'Y': target, 'l': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "train_data = CamVidDataset(csv_file=train_file, phase='train')\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
        "                          shuffle=True, num_workers=8)\n",
        "\n",
        "val_data = CamVidDataset(csv_file=val_file, phase='val', flip_rate=0)\n",
        "val_loader = DataLoader(val_data, batch_size=1, num_workers=8)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training csv exists:True\n",
            "validation csv exists:True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo5Fc4S32Xan",
        "colab_type": "text"
      },
      "source": [
        "## Create Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h-a5moWhLhF",
        "colab_type": "code",
        "outputId": "da2cfa54-303e-4b33-c309-f4f0ba146942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16',\n",
        "                 requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:            \n",
        "            exec(f'self.load_state_dict(models.{model}'\n",
        "                 '(pretrained=True).state_dict())')\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class FCN8s(nn.Module):\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score)                           # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn2(score)                           # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "\n",
        "# load pretrained weights and define FCN8s\n",
        "vgg_model = VGGNet(requires_grad=True, remove_fc=True)\n",
        "fcn_model = FCN8s(pretrained_net=vgg_model, n_class=num_class)\n",
        "\n",
        "ts = time.time()\n",
        "vgg_model = vgg_model.cuda()\n",
        "fcn_model = fcn_model.cuda()\n",
        "fcn_model = nn.DataParallel(fcn_model, device_ids=num_gpu)\n",
        "print(f'Finish cuda loading, time elapsed {time.time() - ts}')\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(fcn_model.parameters(), lr=lr)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:26<00:00, 20.5MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish cuda loading, time elapsed 8.861755609512329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERLOarfL2oQm",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUjPeffKbm36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    for epoch in range(epochs):\n",
        "        ts = time.time()\n",
        "        for iter_, batch in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_gpu:\n",
        "                inputs = Variable(batch['X'].cuda())\n",
        "                labels = Variable(batch['Y'].cuda())\n",
        "            else:\n",
        "                inputs, labels = Variable(batch['X']), Variable(batch['Y'])\n",
        "\n",
        "            outputs = fcn_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if iter_ % 10 == 0:\n",
        "                print(f'epoch{epoch}, iter{iter_}, loss: {loss.data.item():.4f}')\n",
        "        scheduler.step()\n",
        "        print(f'Finish epoch {epoch}, time elapsed {time.time() - ts:.4f}')\n",
        "        val(epoch)\n",
        "\n",
        "    highest_pixel_acc = max(pixel_acc_list)\n",
        "    highest_mIOU = max(mIOU_list)        \n",
        "\n",
        "    highest_pixel_acc_epoch = pixel_acc_list.index(highest_pixel_acc)\n",
        "    highest_mIOU_epoch = mIOU_list.index(highest_mIOU)\n",
        "\n",
        "    print(f'The highest mIOU is {highest_mIOU:.4f}'\n",
        "          f' and is achieved at epoch-{highest_mIOU_epoch}')\n",
        "    print(f'The highest pixel accuracy  is {highest_pixel_acc:.4f}'\n",
        "          f' and is achieved at epoch-{highest_pixel_acc_epoch}')\n",
        "\n",
        "\n",
        "def save_result_comparison(input_np, output_np):\n",
        "    means = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "\n",
        "    global global_index\n",
        "\n",
        "    original_im_RGB = np.zeros((256,256,3))    \n",
        "    original_im_RGB[:,:,0] = input_np[0,0,:,:]    \n",
        "    original_im_RGB[:,:,1] = input_np[0,1,:,:]\n",
        "    original_im_RGB[:,:,2] = input_np[0,2,:,:]\n",
        "\n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0] + means[0]\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1] + means[1]\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2] + means[2]\n",
        "\n",
        "    original_im_RGB[:,:,0] = original_im_RGB[:,:,0]*255.0\n",
        "    original_im_RGB[:,:,1] = original_im_RGB[:,:,1]*255.0\n",
        "    original_im_RGB[:,:,2] = original_im_RGB[:,:,2]*255.0\n",
        "\n",
        "    im_seg_RGB = np.zeros((256,256,3))\n",
        "\n",
        "    # the following version is designed for 11-class version and \n",
        "    # could still work if the number of classes is smaller.\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if output_np[i,j] == 0:  # Sky\n",
        "                im_seg_RGB[i,j,:] = [128, 128, 128]\n",
        "            elif output_np[i,j] == 1:  # Building\n",
        "                im_seg_RGB[i,j,:] = [128, 0, 0]\n",
        "            elif output_np[i,j] == 2:  # Pole\n",
        "                im_seg_RGB[i,j,:] = [192, 192, 128]    \n",
        "            elif output_np[i,j] == 3:  # Road\n",
        "                im_seg_RGB[i,j,:] = [128, 64, 128]    \n",
        "            elif output_np[i,j] == 4:  # Pavement\n",
        "                im_seg_RGB[i,j,:] = [0, 0, 192]    \n",
        "            elif output_np[i,j] == 5:  # Tree\n",
        "                im_seg_RGB[i,j,:] = [128, 128, 0]\n",
        "            elif output_np[i,j] == 6:  # Sign Symbol\n",
        "                im_seg_RGB[i,j,:] = [192, 128, 128]    \n",
        "            elif output_np[i,j] == 7:  # Fence\n",
        "                im_seg_RGB[i,j,:] = [64, 64, 128]    \n",
        "            elif output_np[i,j] == 8:  # Car\n",
        "                im_seg_RGB[i,j,:] = [64, 0, 128]    \n",
        "            elif output_np[i,j] == 9:  # Pedestrian\n",
        "                im_seg_RGB[i,j,:] = [64, 64, 0]    \n",
        "            elif output_np[i,j] == 10:  # Bicyclist\n",
        "                im_seg_RGB[i,j,:] = [0, 128, 192]\n",
        "\n",
        "    # horizontally stack original image and \n",
        "    # its corresponding segmentation results     \n",
        "    hstack_image = np.hstack((original_im_RGB, im_seg_RGB))             \n",
        "    new_im = Image.fromarray(np.uint8(hstack_image))\n",
        "\n",
        "    file_name = folder_to_save_validation_result / (str(global_index) + '.jpg')\n",
        "\n",
        "    global_index += 1\n",
        "\n",
        "    new_im.save(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7cK6h9vkbf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(epoch):\n",
        "    fcn_model.eval()\n",
        "    total_ious = []\n",
        "    pixel_accs = []\n",
        "\n",
        "    for iter_, batch in enumerate(val_loader):\n",
        "        if use_gpu:\n",
        "            inputs = Variable(batch['X'].cuda())\n",
        "        else:\n",
        "            inputs = Variable(batch['X'])        \n",
        "\n",
        "        output = fcn_model(inputs)                                \n",
        "\n",
        "        # only save the 1st image for comparison\n",
        "        if iter_ == 0:\n",
        "            print(f'---------iter={iter_}')\n",
        "            # generate images\n",
        "            images = output.data.max(1)[1].cpu().numpy()[:,:,:]\n",
        "            image = images[0,:,:]        \n",
        "            save_result_comparison(batch['X'], image)\n",
        "\n",
        "        output = output.data.cpu().numpy()\n",
        "\n",
        "        N, _, h, w = output.shape\n",
        "        output = output.transpose(0, 2, 3, 1).reshape(-1, num_class)\n",
        "        pred = output.argmax(axis=1).reshape(N, h, w)\n",
        "        target = batch['l'].cpu().numpy().reshape(N, h, w)\n",
        "\n",
        "        for p, t in zip(pred, target):\n",
        "            total_ious.append(iou(p, t))\n",
        "            pixel_accs.append(pixel_acc(p, t))\n",
        "\n",
        "    # Calculate average IoU\n",
        "    total_ious = np.array(total_ious).T  # n_class * val_len\n",
        "    ious = np.nanmean(total_ious, axis=1)\n",
        "    pixel_accs = np.array(pixel_accs).mean()\n",
        "    print(f'epoch{epoch}, pix_acc: {pixel_accs:.4f},'\n",
        "          f' meanIoU: {np.nanmean(ious):.4f}, IoUs: {np.round(ious, 4)}')\n",
        "\n",
        "    global pixel_acc_list\n",
        "    global mIOU_list\n",
        "\n",
        "    pixel_acc_list.append(pixel_accs)\n",
        "    mIOU_list.append(np.nanmean(ious))\n",
        "\n",
        "\n",
        "def iou(pred, target):\n",
        "    ious = []\n",
        "    for cls in range(num_class):\n",
        "        pred_inds = pred == cls\n",
        "        target_inds = target == cls\n",
        "        intersection = pred_inds[target_inds].sum()\n",
        "        union = pred_inds.sum() + target_inds.sum() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))\n",
        "        else:\n",
        "            ious.append(float(intersection) / max(union, 1))\n",
        "    return ious\n",
        "\n",
        "\n",
        "def pixel_acc(pred, target):\n",
        "    correct = (pred == target).sum()\n",
        "    total   = (target == target).sum()\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKPmSa8W56h2",
        "colab_type": "code",
        "outputId": "957bca77-d103-498d-8142-2a7ba7463edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# perform training and validation\n",
        "val(0)\n",
        "train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------iter=0\n",
            "epoch0, pix_acc: 0.8267, meanIoU: 0.2756, IoUs: [0.     0.8267 0.    ]\n",
            "epoch0, iter0, loss: 0.6790\n",
            "epoch0, iter10, loss: 0.6127\n",
            "epoch0, iter20, loss: 0.5580\n",
            "epoch0, iter30, loss: 0.4583\n",
            "epoch0, iter40, loss: 0.4144\n",
            "epoch0, iter50, loss: 0.3647\n",
            "epoch0, iter60, loss: 0.3260\n",
            "Finish epoch 0, time elapsed 10.9421\n",
            "---------iter=0\n",
            "epoch0, pix_acc: 0.8267, meanIoU: 0.2756, IoUs: [0.     0.8267 0.    ]\n",
            "epoch1, iter0, loss: 0.3170\n",
            "epoch1, iter10, loss: 0.3047\n",
            "epoch1, iter20, loss: 0.1666\n",
            "epoch1, iter30, loss: 0.2478\n",
            "epoch1, iter40, loss: 0.2326\n",
            "epoch1, iter50, loss: 0.2143\n",
            "epoch1, iter60, loss: 0.2842\n",
            "Finish epoch 1, time elapsed 10.8546\n",
            "---------iter=0\n",
            "epoch1, pix_acc: 0.8626, meanIoU: 0.4085, IoUs: [0.3691 0.8563 0.    ]\n",
            "epoch2, iter0, loss: 0.2478\n",
            "epoch2, iter10, loss: 0.1740\n",
            "epoch2, iter20, loss: 0.1221\n",
            "epoch2, iter30, loss: 0.1371\n",
            "epoch2, iter40, loss: 0.1320\n",
            "epoch2, iter50, loss: 0.1131\n",
            "epoch2, iter60, loss: 0.1375\n",
            "Finish epoch 2, time elapsed 10.8032\n",
            "---------iter=0\n",
            "epoch2, pix_acc: 0.9251, meanIoU: 0.6324, IoUs: [0.8683 0.9152 0.1136]\n",
            "epoch3, iter0, loss: 0.1399\n",
            "epoch3, iter10, loss: 0.1247\n",
            "epoch3, iter20, loss: 0.1062\n",
            "epoch3, iter30, loss: 0.0923\n",
            "epoch3, iter40, loss: 0.1113\n",
            "epoch3, iter50, loss: 0.1153\n",
            "epoch3, iter60, loss: 0.0748\n",
            "Finish epoch 3, time elapsed 10.7608\n",
            "---------iter=0\n",
            "epoch3, pix_acc: 0.9401, meanIoU: 0.7660, IoUs: [0.8842 0.9287 0.485 ]\n",
            "epoch4, iter0, loss: 0.1081\n",
            "epoch4, iter10, loss: 0.1032\n",
            "epoch4, iter20, loss: 0.1357\n",
            "epoch4, iter30, loss: 0.1218\n",
            "epoch4, iter40, loss: 0.1256\n",
            "epoch4, iter50, loss: 0.1146\n",
            "epoch4, iter60, loss: 0.0501\n",
            "Finish epoch 4, time elapsed 10.8225\n",
            "---------iter=0\n",
            "epoch4, pix_acc: 0.9381, meanIoU: 0.6771, IoUs: [0.8826 0.9292 0.2196]\n",
            "epoch5, iter0, loss: 0.1123\n",
            "epoch5, iter10, loss: 0.0951\n",
            "epoch5, iter20, loss: 0.0996\n",
            "epoch5, iter30, loss: 0.1012\n",
            "epoch5, iter40, loss: 0.0835\n",
            "epoch5, iter50, loss: 0.1272\n",
            "epoch5, iter60, loss: 0.0555\n",
            "Finish epoch 5, time elapsed 10.7802\n",
            "---------iter=0\n",
            "epoch5, pix_acc: 0.9461, meanIoU: 0.7299, IoUs: [0.8879 0.9375 0.3641]\n",
            "epoch6, iter0, loss: 0.0613\n",
            "epoch6, iter10, loss: 0.1011\n",
            "epoch6, iter20, loss: 0.0581\n",
            "epoch6, iter30, loss: 0.0913\n",
            "epoch6, iter40, loss: 0.0850\n",
            "epoch6, iter50, loss: 0.0809\n",
            "epoch6, iter60, loss: 0.1016\n",
            "Finish epoch 6, time elapsed 10.7671\n",
            "---------iter=0\n",
            "epoch6, pix_acc: 0.9453, meanIoU: 0.7807, IoUs: [0.8915 0.9347 0.5159]\n",
            "epoch7, iter0, loss: 0.1012\n",
            "epoch7, iter10, loss: 0.0820\n",
            "epoch7, iter20, loss: 0.0875\n",
            "epoch7, iter30, loss: 0.0702\n",
            "epoch7, iter40, loss: 0.0957\n",
            "epoch7, iter50, loss: 0.0624\n",
            "epoch7, iter60, loss: 0.1002\n",
            "Finish epoch 7, time elapsed 10.7674\n",
            "---------iter=0\n",
            "epoch7, pix_acc: 0.9539, meanIoU: 0.7986, IoUs: [0.8916 0.9452 0.559 ]\n",
            "epoch8, iter0, loss: 0.0644\n",
            "epoch8, iter10, loss: 0.0848\n",
            "epoch8, iter20, loss: 0.0526\n",
            "epoch8, iter30, loss: 0.0838\n",
            "epoch8, iter40, loss: 0.0768\n",
            "epoch8, iter50, loss: 0.0679\n",
            "epoch8, iter60, loss: 0.0935\n",
            "Finish epoch 8, time elapsed 10.8144\n",
            "---------iter=0\n",
            "epoch8, pix_acc: 0.9469, meanIoU: 0.7827, IoUs: [0.8428 0.9365 0.5688]\n",
            "epoch9, iter0, loss: 0.0708\n",
            "epoch9, iter10, loss: 0.0860\n",
            "epoch9, iter20, loss: 0.0711\n",
            "epoch9, iter30, loss: 0.1078\n",
            "epoch9, iter40, loss: 0.0739\n",
            "epoch9, iter50, loss: 0.0650\n",
            "epoch9, iter60, loss: 0.0550\n",
            "Finish epoch 9, time elapsed 10.8655\n",
            "---------iter=0\n",
            "epoch9, pix_acc: 0.9552, meanIoU: 0.8085, IoUs: [0.8924 0.9464 0.5867]\n",
            "epoch10, iter0, loss: 0.0711\n",
            "epoch10, iter10, loss: 0.0877\n",
            "epoch10, iter20, loss: 0.0743\n",
            "epoch10, iter30, loss: 0.0849\n",
            "epoch10, iter40, loss: 0.0474\n",
            "epoch10, iter50, loss: 0.0762\n",
            "epoch10, iter60, loss: 0.0600\n",
            "Finish epoch 10, time elapsed 10.7885\n",
            "---------iter=0\n",
            "epoch10, pix_acc: 0.9569, meanIoU: 0.8012, IoUs: [0.8906 0.949  0.5638]\n",
            "epoch11, iter0, loss: 0.0732\n",
            "epoch11, iter10, loss: 0.0655\n",
            "epoch11, iter20, loss: 0.0474\n",
            "epoch11, iter30, loss: 0.0636\n",
            "epoch11, iter40, loss: 0.0656\n",
            "epoch11, iter50, loss: 0.1225\n",
            "epoch11, iter60, loss: 0.0683\n",
            "Finish epoch 11, time elapsed 10.7500\n",
            "---------iter=0\n",
            "epoch11, pix_acc: 0.9580, meanIoU: 0.8165, IoUs: [0.8912 0.9501 0.6083]\n",
            "epoch12, iter0, loss: 0.0703\n",
            "epoch12, iter10, loss: 0.0635\n",
            "epoch12, iter20, loss: 0.0472\n",
            "epoch12, iter30, loss: 0.0987\n",
            "epoch12, iter40, loss: 0.0562\n",
            "epoch12, iter50, loss: 0.0807\n",
            "epoch12, iter60, loss: 0.1027\n",
            "Finish epoch 12, time elapsed 10.7950\n",
            "---------iter=0\n",
            "epoch12, pix_acc: 0.9571, meanIoU: 0.7910, IoUs: [0.89   0.9494 0.5337]\n",
            "epoch13, iter0, loss: 0.0566\n",
            "epoch13, iter10, loss: 0.0806\n",
            "epoch13, iter20, loss: 0.0561\n",
            "epoch13, iter30, loss: 0.0598\n",
            "epoch13, iter40, loss: 0.0586\n",
            "epoch13, iter50, loss: 0.0649\n",
            "epoch13, iter60, loss: 0.0666\n",
            "Finish epoch 13, time elapsed 10.6916\n",
            "---------iter=0\n",
            "epoch13, pix_acc: 0.9590, meanIoU: 0.8144, IoUs: [0.8927 0.9513 0.5993]\n",
            "epoch14, iter0, loss: 0.0759\n",
            "epoch14, iter10, loss: 0.0510\n",
            "epoch14, iter20, loss: 0.0306\n",
            "epoch14, iter30, loss: 0.0687\n",
            "epoch14, iter40, loss: 0.0867\n",
            "epoch14, iter50, loss: 0.0516\n",
            "epoch14, iter60, loss: 0.0673\n",
            "Finish epoch 14, time elapsed 10.8952\n",
            "---------iter=0\n",
            "epoch14, pix_acc: 0.9589, meanIoU: 0.8070, IoUs: [0.8998 0.9513 0.5698]\n",
            "epoch15, iter0, loss: 0.0581\n",
            "epoch15, iter10, loss: 0.0647\n",
            "epoch15, iter20, loss: 0.0443\n",
            "epoch15, iter30, loss: 0.0735\n",
            "epoch15, iter40, loss: 0.0527\n",
            "epoch15, iter50, loss: 0.0889\n",
            "epoch15, iter60, loss: 0.0403\n",
            "Finish epoch 15, time elapsed 10.8097\n",
            "---------iter=0\n",
            "epoch15, pix_acc: 0.9594, meanIoU: 0.8194, IoUs: [0.9001 0.9516 0.6066]\n",
            "epoch16, iter0, loss: 0.0808\n",
            "epoch16, iter10, loss: 0.0591\n",
            "epoch16, iter20, loss: 0.0608\n",
            "epoch16, iter30, loss: 0.0560\n",
            "epoch16, iter40, loss: 0.0565\n",
            "epoch16, iter50, loss: 0.0532\n",
            "epoch16, iter60, loss: 0.0393\n",
            "Finish epoch 16, time elapsed 10.9530\n",
            "---------iter=0\n",
            "epoch16, pix_acc: 0.9631, meanIoU: 0.8260, IoUs: [0.9011 0.9561 0.621 ]\n",
            "epoch17, iter0, loss: 0.0754\n",
            "epoch17, iter10, loss: 0.0805\n",
            "epoch17, iter20, loss: 0.0575\n",
            "epoch17, iter30, loss: 0.0649\n",
            "epoch17, iter40, loss: 0.0564\n",
            "epoch17, iter50, loss: 0.0573\n",
            "epoch17, iter60, loss: 0.0501\n",
            "Finish epoch 17, time elapsed 10.9439\n",
            "---------iter=0\n",
            "epoch17, pix_acc: 0.9615, meanIoU: 0.8276, IoUs: [0.8967 0.9543 0.6318]\n",
            "epoch18, iter0, loss: 0.0642\n",
            "epoch18, iter10, loss: 0.0533\n",
            "epoch18, iter20, loss: 0.0454\n",
            "epoch18, iter30, loss: 0.0649\n",
            "epoch18, iter40, loss: 0.0471\n",
            "epoch18, iter50, loss: 0.0704\n",
            "epoch18, iter60, loss: 0.0403\n",
            "Finish epoch 18, time elapsed 10.7372\n",
            "---------iter=0\n",
            "epoch18, pix_acc: 0.9633, meanIoU: 0.8297, IoUs: [0.8991 0.9562 0.6339]\n",
            "epoch19, iter0, loss: 0.0545\n",
            "epoch19, iter10, loss: 0.0791\n",
            "epoch19, iter20, loss: 0.0495\n",
            "epoch19, iter30, loss: 0.0585\n",
            "epoch19, iter40, loss: 0.0715\n",
            "epoch19, iter50, loss: 0.0852\n",
            "epoch19, iter60, loss: 0.0563\n",
            "Finish epoch 19, time elapsed 10.8611\n",
            "---------iter=0\n",
            "epoch19, pix_acc: 0.9625, meanIoU: 0.8366, IoUs: [0.901  0.9552 0.6536]\n",
            "The highest mIOU is 0.8366 and is achieved at epoch-20\n",
            "The highest pixel accuracy  is 0.9633 and is achieved at epoch-19\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}