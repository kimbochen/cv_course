{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of leaf_classify.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gcirp2kcnbuW",
        "YfcgnqHInfAZ",
        "0ddrRNRAopBK",
        "_lZlIZRKot_u",
        "D-ikcVPznxwm",
        "YkkDDXuLn5qn",
        "7OGkAnven-0P",
        "FIeG_buKoF1M",
        "Hl-sewfKoKoE",
        "bN7gbP3noQaX",
        "t9b6tH0ooSX3",
        "IlamnNIwodPE"
      ],
      "authorship_tag": "ABX9TyM/dMUNi5zpAyMxyGpulF7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmachina/cv_course/blob/master/leaf_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcirp2kcnbuW",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqHqoHL6i4Ny",
        "colab_type": "code",
        "outputId": "0955978b-f152-4638-d473-d3adc6c5de35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \n",
        "os.environ['KAGGLE_KEY'] = \n",
        "CONTEST_NAME = 'leaf-classification'\n",
        "\n",
        "!pip install --quiet --upgrade --force-reinstall --no-deps kaggle\n",
        "!kaggle competitions download -q -c {CONTEST_NAME}\n",
        "!unzip -q {CONTEST_NAME}.zip && rm -f {CONTEST_NAME}.zip\n",
        "!unzip -q '*.zip' && rm -f *.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfcgnqHInfAZ",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THVDoBFmhRaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ddrRNRAopBK",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5DwfviQ-Ywg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeafDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_tsfrm):\n",
        "        self.df = dataframe\n",
        "        self.img_dir = Path('/content/images')\n",
        "        self.img_transforms = img_tsfrm\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_dir / f'{self.df.index[idx]}.jpg'\n",
        "        image = self.img_transforms(Image.open(img_path).convert('RGB'))\n",
        "        attr = torch.tensor(self.df.iloc[idx, 1:])\n",
        "        label = torch.tensor(self.df.iloc[idx, 0], dtype=torch.long)\n",
        "\n",
        "        return (image, attr), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rrs2mBmiL3Yq",
        "colab": {}
      },
      "source": [
        "def show_tensor_image(img_tensor):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(img_tensor.numpy().squeeze(), cmap='binary_r')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lZlIZRKot_u",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10WV-ggG7O8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(8, 32, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(90080, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1000, 99)\n",
        "        )\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        x, attr = xb\n",
        "        conv_x = self.conv(x)\n",
        "        x = torch.cat((conv_x, attr), 1)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGf1O5EuY2kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FCNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        input_size, output_size = 192, 10\n",
        "        layers_size = 100\n",
        "\n",
        "        # self.inlayer = nn.Linear(input_size, layers_size)\n",
        "\n",
        "        # self.linear = nn.Sequential(\n",
        "        #     nn.Linear(layers_size, layers_size),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout()\n",
        "        # )\n",
        "\n",
        "        # self.outlayer = nn.Linear(layers_size, output_size)\n",
        "        self.testlayer = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        _, x = xb\n",
        "        # x = self.inlayer(x)\n",
        "        # x = self.linear(x)\n",
        "        # output = self.outlayer(x)\n",
        "        output = self.testlayer(x)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQNSW070Xn7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        m.bias.data.fill_(1)\n",
        "    elif type(m) == nn.Conv2d:\n",
        "        nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-ikcVPznxwm",
        "colab_type": "text"
      },
      "source": [
        "## Model Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkkDDXuLn5qn",
        "colab_type": "text"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR3uNtVrDGyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    # Get raw dataframe\n",
        "    df = pd.read_csv('/content/train.csv', index_col='id')\n",
        "    df['species'] = df['species'].astype('category').cat.codes\n",
        "\n",
        "    # Get dataframes\n",
        "    train_df = df.sample(frac=0.8,random_state=0)\n",
        "    valid_df = df.drop(train_df.index)\n",
        "    test_df = pd.read_csv('/content/test.csv', index_col='id')\n",
        "    dataframes = {\n",
        "        'train': train_df, 'valid': valid_df, 'test': test_df\n",
        "    }\n",
        "\n",
        "    # Batch sizes\n",
        "    batch_sizes = {'train': 32, 'valid': 64, 'test': 64}\n",
        "\n",
        "    # Data transformations\n",
        "    img_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            # transforms.ToPILImage(),\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor()\n",
        "        ]),\n",
        "        'valid': transforms.Compose([\n",
        "            # transforms.ToPILImage(),\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    }\n",
        "    img_transforms['test'] = img_transforms['valid']\n",
        "\n",
        "    # Datasets\n",
        "    datasets = {\n",
        "        x: LeafDataset(dataframes[x], img_transforms[x])\n",
        "        for x in ['train', 'valid', 'test']\n",
        "    }\n",
        "\n",
        "    # Data loaders\n",
        "    dataloaders = {\n",
        "        x: DataLoader(datasets[x], batch_sizes[x], shuffle=True)\n",
        "        for x in ['train', 'valid', 'test']\n",
        "    }\n",
        "\n",
        "    return dataloaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OGkAnven-0P",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr7IQ0QmVBQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    # Neural network\n",
        "    model = FCNet().to(device)\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = F.cross_entropy\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-2, betas = (0.5, 0.999))\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    return model, criterion, optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIeG_buKoF1M",
        "colab_type": "text"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-sewfKoKoE",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRnPUN_QGZT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(model, criterion, opt, scheduler, train_dl, valid_dl, epoch_num):\n",
        "    history = []\n",
        "    for epoch in range(epoch_num):\n",
        "        model.train()\n",
        "        for x_batch, y_batch in train_dl:\n",
        "            loss_batch(model, criterion, x_batch, y_batch, opt, scheduler)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, criterion, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        valid_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        print(f'Epoch {epoch}/{epoch_num} --- Loss: {valid_loss:.5f}')\n",
        "        history.append([epoch, valid_loss])\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN7gbP3noQaX",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxH8eiOTl7Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, criterion, test_dl):\n",
        "    return 39"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9b6tH0ooSX3",
        "colab_type": "text"
      },
      "source": [
        "### Loss Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nby8kZB0OXYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch(model, criterion, xb, yb, optimizer=None, scheduler=None):\n",
        "    x_batch, y_batch = (xb[0].to(device), xb[1].to(device)), yb.to(device)\n",
        "    pred = model(x_batch)\n",
        "    set_trace()\n",
        "    loss = criterion(pred, y_batch)\n",
        "\n",
        "    if optimizer is not None:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    return loss.item(), yb.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlamnNIwodPE",
        "colab_type": "text"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g2goRcoqs6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = get_data()\n",
        "model = get_model()\n",
        "history = fit(*model, dataloader['train'], dataloader['valid'], epoch_num=400)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}